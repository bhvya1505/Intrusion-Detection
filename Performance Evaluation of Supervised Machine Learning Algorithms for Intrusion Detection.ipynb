{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "Intrusion detection system plays an important role in network security. Intrusion detection model is a predictive model used to predict the network data traffic as normal or intrusion. \n",
    "\n",
    "The objective of this project is to implement [this](https://www.researchgate.net/publication/306361859_Performance_Evaluation_of_Supervised_Machine_Learning_Algorithms_for_Intrusion_Detection) paper wherein classification and predictive models for intrusion detection are built by using machine learning classification algorithms namely Logistic Regression, Gaussian Naive Bayes, Support Vector Machine and Random Forest. We have added 2 more algorithms namely Gradient Boosting and Multilayer Perceptron. These algorithms are tested on the [NSL-KDD](https://www.kaggle.com/hassan06/nslkdd/kernels) data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the NSL-KDD data set\n",
    "Intrusion Detection Systems (IDS) are trained on internet traffic record data. The most common data set is the NSL-KDD, and is the benchmark for modern-day internet traffic.\n",
    "\n",
    "The NSL-KDD data set has the following advantages over the original KDD data set:\n",
    "- It does not include redundant records in the train set, so the classifiers will not be biased towards more frequent records.\n",
    "- There is no duplicate records in the proposed test sets; therefore, the performance of the learners are not biased by the methods which have better detection rates on the frequent records.\n",
    "- The number of selected records from each difficultylevel group is inversely proportional to the percentage of records in the original KDD data set. As a result, the classification rates of distinct machine learning methods vary in a wider range, which makes it more efficient to have an accurate evaluation of different learning techniques.\n",
    "- The number of records in the train and test sets are reasonable, which makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research works will be consistent and comparable.\n",
    "\n",
    "### Data files\n",
    "\n",
    "- KDDTrain+.ARFF: The full NSL-KDD train set with binary labels in ARFF format\n",
    "- KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format\n",
    "- KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file\n",
    "- KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file\n",
    "- KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format\n",
    "- KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n",
    "- KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n",
    "- KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21\n",
    "\n",
    "We will be using KDDTrain+ as train and KDDTest+ as test data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attacks\n",
    "The NSL-KDD data set contains a total of 39 attacks which can be classified into 4 categories: Denial of Service (DoS), Probe, User to Root(U2R), and Remote to Local (R2L). These attacks are identified based on the combination of the 41 features available. A brief description of each category can be seen below:\n",
    "\n",
    "1. DoS is an attack that tries to shut down traffic flow to and from the target system. The IDS is flooded with an abnormal amount of traffic, which the system can’t handle, and shuts down to protect itself. This prevents normal traffic from visiting a network. An example of this could be an online retailer getting flooded with online orders on a day with a big sale, and because the network can’t handle all the requests, it will shut down preventing paying customers to purchase anything. This is the most common attack in the data set. Examples: Neptune, Teardrop and Smurf.\n",
    "\n",
    "\n",
    "2. Probe or surveillance is an attack that tries to get information from a network. The goal here is to act like a thief and steal important information, whether it be personal information about clients or banking information. Examples: ipsweep, nmap attacks.\n",
    "\n",
    "\n",
    "3. U2R is an attack that starts off with a normal user account and tries to gain access to the system or network, as a super-user (root). The attacker attempts to exploit the vulnerabilities in a system to gain root privileges/access. Examples: Perl, Load Module and Eject attacks.\n",
    "\n",
    "\n",
    "4. R2L is an attack that tries to gain local access to a remote machine. An attacker does not have local access to the system/network, and tries to “hack” their way into the network. Examples: imap, guess password and ftp-write attacks.\n",
    "\n",
    "It is noticed from the descriptions above that DoS acts differently from the other three attacks, where DoS attempts to shut down a system to stop traffic flow altogether, whereas the other three attempts to quietly infiltrate the system undetected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data sets and Initial Exploration\n",
    "Let's begin with importing the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the '.txt' files are stored in CSV format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>8</td>\n",
       "      <td>udp</td>\n",
       "      <td>private</td>\n",
       "      <td>SF</td>\n",
       "      <td>105</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>smtp</td>\n",
       "      <td>SF</td>\n",
       "      <td>2231</td>\n",
       "      <td>384</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>klogin</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>neptune</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1         2   3     4     5   6   7   8   9   ...    33    34  \\\n",
       "0        0  tcp  ftp_data  SF   491     0   0   0   0   0  ...  0.17  0.03   \n",
       "1        0  udp     other  SF   146     0   0   0   0   0  ...  0.00  0.60   \n",
       "2        0  tcp   private  S0     0     0   0   0   0   0  ...  0.10  0.05   \n",
       "3        0  tcp      http  SF   232  8153   0   0   0   0  ...  1.00  0.00   \n",
       "4        0  tcp      http  SF   199   420   0   0   0   0  ...  1.00  0.00   \n",
       "...     ..  ...       ...  ..   ...   ...  ..  ..  ..  ..  ...   ...   ...   \n",
       "125968   0  tcp   private  S0     0     0   0   0   0   0  ...  0.10  0.06   \n",
       "125969   8  udp   private  SF   105   145   0   0   0   0  ...  0.96  0.01   \n",
       "125970   0  tcp      smtp  SF  2231   384   0   0   0   0  ...  0.12  0.06   \n",
       "125971   0  tcp    klogin  S0     0     0   0   0   0   0  ...  0.03  0.05   \n",
       "125972   0  tcp  ftp_data  SF   151     0   0   0   0   0  ...  0.30  0.03   \n",
       "\n",
       "          35    36    37    38    39    40       41  42  \n",
       "0       0.17  0.00  0.00  0.00  0.05  0.00   normal  20  \n",
       "1       0.88  0.00  0.00  0.00  0.00  0.00   normal  15  \n",
       "2       0.00  0.00  1.00  1.00  0.00  0.00  neptune  19  \n",
       "3       0.03  0.04  0.03  0.01  0.00  0.01   normal  21  \n",
       "4       0.00  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
       "...      ...   ...   ...   ...   ...   ...      ...  ..  \n",
       "125968  0.00  0.00  1.00  1.00  0.00  0.00  neptune  20  \n",
       "125969  0.01  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
       "125970  0.00  0.00  0.72  0.00  0.01  0.00   normal  18  \n",
       "125971  0.00  0.00  1.00  1.00  0.00  0.00  neptune  20  \n",
       "125972  0.30  0.00  0.00  0.00  0.00  0.00   normal  21  \n",
       "\n",
       "[125973 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('KDDTrain+.txt', header=None)\n",
    "test = pd.read_csv('KDDTest+.txt', header=None)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data sets contain the records of the internet traffic seen by a simple intrusion detection network and are the ghosts of the traffic encountered by a real IDS and just the traces of its existence remains. The data set contains 43 features per record, with 41 of the features referring to the traffic input itself and the last two are labels (whether it is a normal or attack) and Score (the severity of the traffic input itself).\n",
    "\n",
    "A description of each feature and a breakdown of the data set can be seen in the google spreadsheet [here](https://docs.google.com/spreadsheets/d/1oAx320Vo9Z6HrBrL6BcfLH6sh2zIk9EKCv2OlaMGmwY/edit#gid=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the label (column index 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal             67343\n",
       "neptune            41214\n",
       "satan               3633\n",
       "ipsweep             3599\n",
       "portsweep           2931\n",
       "smurf               2646\n",
       "nmap                1493\n",
       "back                 956\n",
       "teardrop             892\n",
       "warezclient          890\n",
       "pod                  201\n",
       "guess_passwd          53\n",
       "buffer_overflow       30\n",
       "warezmaster           20\n",
       "land                  18\n",
       "imap                  11\n",
       "rootkit               10\n",
       "loadmodule             9\n",
       "ftp_write              8\n",
       "multihop               7\n",
       "phf                    4\n",
       "perl                   3\n",
       "spy                    2\n",
       "Name: 41, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[:,41].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal             9711\n",
       "neptune            4657\n",
       "guess_passwd       1231\n",
       "mscan               996\n",
       "warezmaster         944\n",
       "apache2             737\n",
       "satan               735\n",
       "processtable        685\n",
       "smurf               665\n",
       "back                359\n",
       "snmpguess           331\n",
       "saint               319\n",
       "mailbomb            293\n",
       "snmpgetattack       178\n",
       "portsweep           157\n",
       "ipsweep             141\n",
       "httptunnel          133\n",
       "nmap                 73\n",
       "pod                  41\n",
       "buffer_overflow      20\n",
       "multihop             18\n",
       "named                17\n",
       "ps                   15\n",
       "sendmail             14\n",
       "xterm                13\n",
       "rootkit              13\n",
       "teardrop             12\n",
       "xlock                 9\n",
       "land                  7\n",
       "xsnoop                4\n",
       "ftp_write             3\n",
       "perl                  2\n",
       "loadmodule            2\n",
       "udpstorm              2\n",
       "sqlattack             2\n",
       "worm                  2\n",
       "phf                   2\n",
       "imap                  1\n",
       "Name: 41, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[:,41].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "We combine the train and test data sets because the train data set only contains 23 kinds of attacks, while the test data set has 39.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train,test],axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148512</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>smtp</td>\n",
       "      <td>SF</td>\n",
       "      <td>794</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>141</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148513</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>317</td>\n",
       "      <td>938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148514</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>54540</td>\n",
       "      <td>8314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148515</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>domain_u</td>\n",
       "      <td>SF</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>252</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148516</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>sunrpc</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148517 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1         2    3      4     5  6  7  8  9  ...   32    33    34  \\\n",
       "0       0  tcp  ftp_data   SF    491     0  0  0  0  0  ...   25  0.17  0.03   \n",
       "1       0  udp     other   SF    146     0  0  0  0  0  ...    1  0.00  0.60   \n",
       "2       0  tcp   private   S0      0     0  0  0  0  0  ...   26  0.10  0.05   \n",
       "3       0  tcp      http   SF    232  8153  0  0  0  0  ...  255  1.00  0.00   \n",
       "4       0  tcp      http   SF    199   420  0  0  0  0  ...  255  1.00  0.00   \n",
       "...    ..  ...       ...  ...    ...   ... .. .. .. ..  ...  ...   ...   ...   \n",
       "148512  0  tcp      smtp   SF    794   333  0  0  0  0  ...  141  0.72  0.06   \n",
       "148513  0  tcp      http   SF    317   938  0  0  0  0  ...  255  1.00  0.00   \n",
       "148514  0  tcp      http   SF  54540  8314  0  0  0  2  ...  255  1.00  0.00   \n",
       "148515  0  udp  domain_u   SF     42    42  0  0  0  0  ...  252  0.99  0.01   \n",
       "148516  0  tcp    sunrpc  REJ      0     0  0  0  0  0  ...   21  0.08  0.03   \n",
       "\n",
       "          35    36    37    38    39    40  target  \n",
       "0       0.17  0.00  0.00  0.00  0.05  0.00       0  \n",
       "1       0.88  0.00  0.00  0.00  0.00  0.00       0  \n",
       "2       0.00  0.00  1.00  1.00  0.00  0.00       1  \n",
       "3       0.03  0.04  0.03  0.01  0.00  0.01       0  \n",
       "4       0.00  0.00  0.00  0.00  0.00  0.00       0  \n",
       "...      ...   ...   ...   ...   ...   ...     ...  \n",
       "148512  0.01  0.01  0.01  0.00  0.00  0.00       0  \n",
       "148513  0.01  0.01  0.01  0.00  0.00  0.00       0  \n",
       "148514  0.00  0.00  0.00  0.00  0.07  0.07       1  \n",
       "148515  0.00  0.00  0.00  0.00  0.00  0.00       0  \n",
       "148516  0.00  0.00  0.00  0.00  0.44  1.00       1  \n",
       "\n",
       "[148517 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['target'] = train.iloc[:,41].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "train.drop(columns=[41,42], inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [1,2,3]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical:\n",
    "    train.iloc[:,col] = pd.Series(encoder.fit_transform(train.iloc[:,col]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='target',axis=1)\n",
    "y = train.target\n",
    "scaler = StandardScaler()\n",
    "scaled_X = pd.DataFrame(scaler.fit_transform(X))\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(scaled_X,y,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:   17.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    2.1s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9994703152073402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.9954214920549421\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     19264\n",
      "           1       0.99      1.00      1.00     17866\n",
      "\n",
      "    accuracy                           1.00     37130\n",
      "   macro avg       1.00      1.00      1.00     37130\n",
      "weighted avg       1.00      1.00      1.00     37130\n",
      "\n",
      "Average weighted precision:  0.9961938878316355\n",
      "Average weighted recall:  0.9943016759776536\n",
      "Average weighted f1 score:  0.9952468825141195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "rf_mod = RandomForestClassifier(n_estimators=200, criterion='entropy', random_state= 10, verbose= 1)\n",
    "rf_mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: \",rf_mod.score(X_train, y_train))\n",
    "\n",
    "pred_rf = rf_mod.predict(X_test)\n",
    "print('Test score:',rf_mod.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification report: \",classification_report(pred_rf,y_test))\n",
    "\n",
    "print(\"Average weighted precision: \",precision_score(y_test,pred_rf))\n",
    "print(\"Average weighted recall: \",recall_score(y_test,pred_rf))\n",
    "print(\"Average weighted f1 score: \",f1_score(y_test,pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9836875039277474\n",
      "Test score: 0.9828709938055481\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98     19410\n",
      "           1       0.98      0.99      0.98     17720\n",
      "\n",
      "    accuracy                           0.98     37130\n",
      "   macro avg       0.98      0.98      0.98     37130\n",
      "weighted avg       0.98      0.98      0.98     37130\n",
      "\n",
      "Average weighted precision:  0.9871331828442438\n",
      "Average weighted recall:  0.9772067039106145\n",
      "Average weighted f1 score:  0.9821448624368333\n"
     ]
    }
   ],
   "source": [
    "svm_mod = SVC(probability=True)\n",
    "svm_mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: \",svm_mod.score(X_train, y_train))\n",
    "\n",
    "pred_svc = svm_mod.predict(X_test)\n",
    "print('Test score:',svm_mod.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification report: \",classification_report(pred_svc,y_test))\n",
    "\n",
    "print(\"Average weighted precision: \",precision_score(y_test,pred_svc))\n",
    "print(\"Average weighted recall: \",recall_score(y_test,pred_svc))\n",
    "print(\"Average weighted f1 score: \",f1_score(y_test,pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.9361954267553664\n",
      "Test score: 0.9373552383517372\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94     19840\n",
      "           1       0.92      0.95      0.93     17290\n",
      "\n",
      "    accuracy                           0.94     37130\n",
      "   macro avg       0.94      0.94      0.94     37130\n",
      "weighted avg       0.94      0.94      0.94     37130\n",
      "\n",
      "Average weighted precision:  0.9503759398496241\n",
      "Average weighted recall:  0.9179888268156424\n",
      "Average weighted f1 score:  0.9339016766126741\n"
     ]
    }
   ],
   "source": [
    "lg_mod = LogisticRegression()\n",
    "lg_mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: \",lg_mod.score(X_train, y_train))\n",
    "\n",
    "pred_lg = lg_mod.predict(X_test)\n",
    "print('Test score:',lg_mod.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification report: \",classification_report(pred_lg,y_test))\n",
    "\n",
    "print(\"Average weighted precision: \",precision_score(y_test,pred_lg))\n",
    "print(\"Average weighted recall: \",recall_score(y_test,pred_lg))\n",
    "print(\"Average weighted f1 score: \",f1_score(y_test,pred_lg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score:  0.8799680393582734\n",
      "Test score: 0.8808241314301104\n",
      "Classification report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89     19399\n",
      "           1       0.87      0.88      0.88     17731\n",
      "\n",
      "    accuracy                           0.88     37130\n",
      "   macro avg       0.88      0.88      0.88     37130\n",
      "weighted avg       0.88      0.88      0.88     37130\n",
      "\n",
      "Average weighted precision:  0.87998420844848\n",
      "Average weighted recall:  0.8716759776536313\n",
      "Average weighted f1 score:  0.8758103898290813\n"
     ]
    }
   ],
   "source": [
    "gnb_mod = GaussianNB()\n",
    "gnb_mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: \",gnb_mod.score(X_train, y_train))\n",
    "\n",
    "pred_nb = gnb_mod.predict(X_test)\n",
    "print('Test score:',gnb_mod.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification report: \",classification_report(pred_nb,y_test))\n",
    "\n",
    "print(\"Average weighted precision: \",precision_score(y_test,pred_nb))\n",
    "print(\"Average weighted recall: \",recall_score(y_test,pred_nb))\n",
    "print(\"Average weighted f1 score: \",f1_score(y_test,pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_mod = GradientBoostingClassifier(n_estimators=200, random_state= 10)\n",
    "gb_mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: \",gb_mod.score(X_train, y_train))\n",
    "\n",
    "pred_gb = gb_mod.predict(X_test)\n",
    "print('Test score:',gb_mod.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification report: \",classification_report(pred_gb,y_test))\n",
    "\n",
    "print(\"Average weighted precision: \",precision_score(y_test,pred_gb))\n",
    "print(\"Average weighted recall: \",recall_score(y_test,pred_gb))\n",
    "print(\"Average weighted f1 score: \",f1_score(y_test,pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_mod = MLPClassifier(hidden_layer_sizes=[100,50])\n",
    "mlp_mod.fit(X_train, y_train)\n",
    "\n",
    "print(\"Train score: \",mlp_mod.score(X_train, y_train))\n",
    "\n",
    "pred_mlp = mlp_mod.predict(X_test)\n",
    "print('Test score:',mlp_mod.score(X_test, y_test))\n",
    "\n",
    "print(\"Classification report: \",classification_report(pred_mlp,y_test))\n",
    "\n",
    "print(\"Average weighted precision: \",precision_score(y_test,pred_mlp))\n",
    "print(\"Average weighted recall: \",recall_score(y_test,pred_mlp))\n",
    "print(\"Average weighted f1 score: \",f1_score(y_test,pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_skill_prob = [0 for _ in range(len(y_test))]\n",
    "no_skill_auc = roc_auc_score(y_test, no_skill_prob)\n",
    "print(\"No Skill AUC: \", no_skill_auc)\n",
    "ns_fpr, ns_tpr, _ = roc_curve(y_test, no_skill_prob)\n",
    "\n",
    "rf_prob = rf_mod.predict_proba(X_test)[:,-1]\n",
    "rf_auc = roc_auc_score(y_test,rf_prob)\n",
    "print(\"RandomForest AUC: \", rf_auc)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(y_test, rf_prob)\n",
    "\n",
    "svm_prob = svm_mod.predict_proba(X_test)[:,-1]\n",
    "svm_auc = roc_auc_score(y_test,svm_prob)\n",
    "print(\"Support Vector Machine AUC: \", svm_auc)\n",
    "svm_fpr, svm_tpr, _ = roc_curve(y_test, svm_prob)\n",
    "\n",
    "lg_prob = lg_mod.predict_proba(X_test)[:,-1]\n",
    "lg_auc = roc_auc_score(y_test, lg_prob)\n",
    "print(\"Logistic Regression AUC: \",lg_auc)\n",
    "lg_fpr, lg_tpr, _ = roc_curve(y_test, lg_prob)\n",
    "\n",
    "nb_prob = gnb_mod.predict_proba(X_test)[:,-1]\n",
    "nb_auc = roc_auc_score(y_test, nb_prob)\n",
    "print(\"Gaussian Naive Bayes AUC: \", nb_auc)\n",
    "nb_fpr, nb_tpr, _ = roc_curve(y_test, nb_prob)\n",
    "\n",
    "gb_prob = gb_mod.predict_proba(X_test)[:,-1]\n",
    "gb_auc = roc_auc_score(y_test, gb_prob)\n",
    "print(\"GradientBoosting AUC: \", gb_auc)\n",
    "gb_fpr, gb_tpr, _ = roc_curve(y_test, gb_prob)\n",
    "\n",
    "mlp_prob = mlp_mod.predict_proba(X_test)[:,-1]\n",
    "mlp_auc = roc_auc_score(y_test, mlp_prob)\n",
    "print(\"MultiLayer Perceptron AUC: \", mlp_auc)\n",
    "mlp_fpr, mlp_tpr, _ = roc_curve(y_test, mlp_prob)\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(ns_fpr, ns_tpr, linestyle= '--', label= 'Reference')\n",
    "ax.plot(rf_fpr, rf_tpr, linestyle= '-', label= 'RandomForest')\n",
    "ax.plot(svm_fpr, svm_tpr, linestyle= '-', label= 'SupportVectorMachine')\n",
    "ax.plot(lg_fpr, lg_tpr, linestyle='-', label= 'LogisticRegression')\n",
    "ax.plot(nb_fpr, nb_tpr, linestyle='-', label= 'GaussianNB')\n",
    "ax.plot(gb_fpr, gb_tpr, linestyle='-', label= 'GradientBoosting')\n",
    "ax.plot(mlp_fpr, mlp_tpr, linestyle='-', label= 'MultiLayer Perceptron')\n",
    "plt.xlabel('False Positve rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC curve')\n",
    "ax.legend(loc=\"bottom right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(ns_fpr, ns_tpr, linestyle= '--', label= 'Reference')\n",
    "ax.plot(rf_fpr, rf_tpr, linestyle= '-', label= 'RandomForest')\n",
    "ax.plot(svm_fpr, svm_tpr, linestyle= '-', label= 'SupportVectorMachine')\n",
    "ax.plot(lg_fpr, lg_tpr, linestyle='-', label= 'LogisticRegression')\n",
    "ax.plot(nb_fpr, nb_tpr, linestyle='-', label= 'GaussianNB')\n",
    "ax.plot(gb_fpr, gb_tpr, linestyle='-', label= 'GradientBoosting')\n",
    "ax.plot(mlp_fpr, mlp_tpr, linestyle='-', label= 'MultiLayer Perceptron')\n",
    "plt.xlabel('False Positve rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.title('ROC curve (Zoomed on top right)')\n",
    "plt.xlim([0,0.2])\n",
    "plt.ylim([0.8,1])\n",
    "ax.legend(loc=\"bottom right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_x, rf_y = calibration_curve(y_test, rf_prob, n_bins=10)\n",
    "sv_x, sv_y = calibration_curve(y_test, svm_prob, n_bins=10)\n",
    "lg_x, lg_y = calibration_curve(y_test, lg_prob, n_bins=10)\n",
    "nb_x, nb_y = calibration_curve(y_test, nb_prob, n_bins=10)\n",
    "gb_x, gb_y = calibration_curve(y_test, gb_prob, n_bins=10)\n",
    "mlp_x, mlp_y = calibration_curve(y_test, mlp_prob, n_bins=10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(rf_x, rf_y, marker= 'o', linewidth= '1', label= 'RandomForest')\n",
    "ax.plot(sv_x, sv_y, marker= 'o', linewidth= '1', label= 'SupportVector Machine')\n",
    "ax.plot(lg_x, lg_y, marker= 'o', linewidth= '1', label= 'LogisticRegression')\n",
    "ax.plot(nb_x, nb_y, marker= 'o', linewidth= '1', label= 'GaussianNB')\n",
    "# ax.plot(gb_x, gb_y, marker= 'o', linewidth= '1', label= 'GradientBoosting')\n",
    "# ax.plot(mlp_x, mlp_y, marker= 'o', linewidth= '1', label= 'MultiLayer Perceptron')\n",
    "\n",
    "line = mlines.Line2D([0,1],[0,1], color='black')\n",
    "ax.add_line(line)\n",
    "ax.legend()\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Calibration curve')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
